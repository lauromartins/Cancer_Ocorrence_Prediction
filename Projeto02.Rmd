---
title: "DESCRICAO DO PROJETO"
author: "Lauro C. M. de Paula"
date: "26/10/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Projeto 2 - Prevendo a Ocorrencia de Cancer

Este projeto é parte integrante do curso Big Data Analytics com R e Microsoft Azure da Formação Cientista de Dados. O objetivo é analisar dados reais sobre exames de câncer de mama realizado com mulheres nos EUA e, então, prever a ocorrência de novos casos.

Os dados do câncer da mama incluem 569 observações de biópsias de câncer, cada um com 32 características (variáveis). Uma característica é um número de identificação (ID), outra é o diagnóstico de câncer, e 30 são medidas laboratoriais numéricas. O diagnóstico é codificado como "M" para indicar maligno ou "B" para indicar benigno. Todo o projeto está descrito de acordo com suas etapas. 



## Etapa 1 - Coletando os Dados

#Aqui está a coleta de dados. Neste caso, um arquivo csv.


```{r coleta}
# Coletando dados
dados <- read.csv("http://datascienceacademy.com.br/blog/aluno/RFundamentos/Datasets/ML/bc_data.csv", 
                  stringsAsFactors = FALSE)
str(dados)
#head(dados)
```


## Etapa 2 - Explorando os Dados

Independentemente do método de aprendizagem de máquina, deve sempre ser excluídas variáveis de ID. Caso contrário, isso pode levar a resultados errados porque o ID pode ser usado para unicamente "prever" cada exemplo. 


```{r explorando}
# Excluindo a coluna ID
dados <- dados[-1]
str(dados)

# Verificando se existem dados NA
any(is.na(dados))

# Muitos classificadores requerem que as variaveis sejam do tipo Fator
table(dados$diagnosis)
dados$diagnosis <- factor(dados$diagnosis, levels = c("B", "M"), labels = c("Benigno", "Maligno"))
str(dados$diagnosis)

# Verificando a proporco
round(prop.table(table(dados$diagnosis)) * 100, digits = 1) 

# Medidas de Tendencia Cetral
# Detectamos aqui um problema de escala entre os dados, que precisam ser normalizados
summary(dados[c("radius_mean", "area_mean", "smoothness_mean")])

# Criando um funcao de normalizacao
normalizar <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# Testando a funcao de normalizacao - os resultados devem ser identicos
#normalizar(c(1, 2, 3, 4, 5))
#normalizar(c(10, 20, 30, 40, 50))

# Normalizando os dados
dados_norm <- as.data.frame(lapply(dados[2:31], normalizar))

# Confirmando que a normalizacao funcionou
summary(dados[c("radius_mean", "area_mean", "smoothness_mean")])
summary(dados_norm[c("radius_mean", "area_mean", "smoothness_mean")])
```



## Etapa 3 - Treinando o modelo

Com os dados devidamente normalizados, podemos agora comecar o processo de treinamento do modelo. Para isso, vamos dividir nosso conjunto de dados em dados de treino e dados de teste.


```{r treinamento}
# Carregando o pacote library
# install.packages("class")
library(class)

# Criando dados de treino e dados de teste - os dados podem também ser selecionados aleatoriamente
dados_treino <- dados_norm[1:469, ]
dados_teste <- dados_norm[470:569, ]

# Criando os labels para os dados de treino e de teste
dados_treino_labels <- dados[1:469, 1]
dados_teste_labels <- dados[470:569, 1]

#?knn
# Criando o modelo
modelo <- knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k = 21)

# A funcao knn() retorna um objeto do tipo fator com as previsÃµes para cada exemplo no dataset de teste
class(modelo)

```




## Etapa 4 - Avaliando a Performance do Modelo


```{r performance}
# Carregando o gmodels
# install.packages("gmodels")
library(gmodels)

# Criando uma tabel acruzada dos dados previstos x dados atuais
CrossTable(x = dados_teste_labels, y = modelo, prop.chisq = FALSE)


# Interpretando os Resultados
# A tabela cruzada mostra 4 possiveis valores, que representam os falso/verdadeiro positivo e negativo
# A primeira coluna lista os labels originais nos dados observados
# As duas colunas do modelo (Benigno e Maligno) do modelo, mostram os resultados da previsao
# Temos:
# Cenario 1: Celula Benigno (label) x Benigno (Modelo) - 61 casos - true negative 
# Cenario 2: Celula Benigno (label) x Maligno (Modelo) - 00 casos - false positive 
# Cenario 3: Celula Maligno (label) x Benigno (Modelo) - 02 casos - false negative (o modelo errou)
# Cenario 4: Celula Maligno (label) x Maligno (Modelo) - 37 casos - true positive 


# Lendo a Confusion Matrix (Perspectva de ter ou nao a doenca):

# True Negative  = nosso modelo previu que a pessoa NAO tinha a doenca e os dados mostraram que realmente a pessoa NAO tinha a doenca
# False Positive = nosso modelo previu que a pessoa tinha a doenca e os dados mostraram que NAO, a pessoa tinha a doenca
# False Negative = nosso modelo previu que a pessoa NAO tinha a doenca e os dados mostraram que SIM, a pessoa tinha a doenca
# True Positive = nosso modelo previu que a pessoa tinha a doenca e os dados mostraram que SIM, a pessoa tinha a doenca

# Falso Positivo - Erro Tipo I
# Falso Negativo - Erro Tipo II

# Taxa de acerto do Modelo: 98% (acertou 98 em 100)

```




## Etapa 5 - Otimizacao do Modelo
 
 
```{r otimizacao}
## Etapa 5: Otimizando a perfomance do modelo

# Usando a funcao scale() para padronizar o z-score 
dados_z <- as.data.frame(scale(dados[-1]))

# Confirmando transformacao realizada com sucesso
summary(dados_z$area_mean)

# Criando novos datasets de treino e de teste
dados_treino <- dados_z[1:469, ]
dados_teste <- dados_z[470:569, ]

dados_treino_labels <- dados[ 1: 469, 1] 
dados_teste_labels <- dados[ 470: 569, 1]

# Reclassificando
modelo_v2 <- knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k = 21)

# Criando a cross table para comparar dados previstos com os dados reais
CrossTable(x = dados_teste_labels, y = modelo_v2, prop.chisq = FALSE)


# Testando diferentes valores para k
# Criando dados de treino e dados de teste
# dados_treino <- dados_norm[1:469, ]
# dados_teste <- dados_norm[470:569, ]

# Criando os labels para os dados de treino e de teste
# dados_treino_labels <- dados[1:469, 1]
# dados_teste_labels <- dados[470:569, 1]

# dados_test_pred <- knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k=1)
# CrossTable(x = dados_teste_labels, y = dados_test_pred, prop.chisq=FALSE)

# dados_test_pred <- knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k=5)
# CrossTable(x = dados_teste_labels, y = dados_test_pred, prop.chisq=FALSE)

# dados_test_pred <- knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k=11)
# CrossTable(x = dados_teste_labels, y = dados_test_pred, prop.chisq=FALSE)

# dados_test_pred <- knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k=15)
# CrossTable(x = dados_teste_labels, y = dados_test_pred, prop.chisq=FALSE)

# dados_test_pred <- knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k=21)
# CrossTable(x = dados_teste_labels, y = dados_test_pred, prop.chisq=FALSE)

# dados_test_pred <- knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k=27)
# CrossTable(x = dados_teste_labels, y = dados_test_pred, prop.chisq=FALSE)
```




## Etapa 6 - Calculando a Taxa de Erro


```{r taxaerro}
## Calculando a taxa de erro
prev = NULL
taxa_erro = NULL

suppressWarnings(
for(i in 1:20){
  set.seed(101)
  prev = knn(train = dados_treino, test = dados_teste, cl = dados_treino_labels, k = i)
  taxa_erro[i] = mean(dados$diagnosis != prev)
})

# Obtendo os valores de k e das taxas de erro
library(ggplot2)
k.values <- 1:20
df_erro <- data.frame(taxa_erro, k.values)
df_erro

# Na medida que aumentamos k, diminuimos a taxa de erro do modelo
ggplot(df_erro, aes(x = k.values, y = taxa_erro)) + geom_point()+ geom_line(lty = "dotted", color = 'red')




```




